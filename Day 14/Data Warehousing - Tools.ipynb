{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8c4bc666-34a1-47b6-8018-1ad79dafae95",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #add8e6; padding: 10px; height: 70px; border-radius: 15px;\">\n",
    "    <div style=\"font-family: 'Georgia', serif; font-size: 20px; padding: 10px; text-align: right; position: absolute; right: 20px;\">\n",
    "        Mohammad Idrees Bhat <br>\n",
    "        <span style=\"font-family: 'Arial', sans-serif;font-size: 12px; color: #0a0a0a;\">Tech Skills Trainer | AI/ML Consultant</span> <!--- Mohammad Idrees Bhat | Tech Skills Trainer | AI/ML Consultant --->\n",
    "    </div>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef444d2e-97e9-49a8-bf3d-0119a2dfebb5",
   "metadata": {},
   "source": [
    "<!--- Mohammad Idrees Bhat | Tech Skills Trainer | AI/ML Consultant --->"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "151ad3d8-0bce-4e29-86da-5ea91b5a69df",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #002147; padding: 10px; text-align: center; color: white; font-size: 32px; font-family: 'Arial', sans-serif;\">\n",
    "    Data Warehousing - Tools <br>\n",
    "    <h3 style=\"text-align: center; color: white; font-size: 15px; font-family: 'Arial', sans-serif;\">ETL processes with Apache Airflow and Amazon Redshift</h3>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8978fea-cbf0-4fc7-b62e-58e2f0297b44",
   "metadata": {},
   "source": [
    "## AGENDA\n",
    "1. Tools"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19b1c30b-e766-4658-8d70-1b0af10ae2f4",
   "metadata": {},
   "source": [
    "<!-- Link the Montserrat font -->\n",
    "<link href=\"https://fonts.googleapis.com/css2?family=Montserrat:wght@700&display=swap\" rel=\"stylesheet\">\n",
    "\n",
    "<!-- Main div with centered content and a flexible box size, no scroll bar -->\n",
    "<div style=\"background-color: #baf733; min-height: 100px; width: 100%; display: flex; justify-content: center; align-items: center; position: relative; padding: 20px; box-sizing: border-box; font-family: 'Montserrat', sans-serif; font-weight: 700; font-size: 20px; border-radius: 15px;\">\n",
    "    <div style=\"position: absolute; top: 10px; right: 10px; padding: 5px 10px; font-size: 14px; color: rgba(0, 0, 0, 0.05); border-radius: 10px;\">Mohammad Idrees Bhat</div>\n",
    "    <!-- Fill the below text with question -->\n",
    "    <!-- Fill the below text with question -->\n",
    "   Whatâ€™s a skill you wish you could magically acquire overnight?\n",
    "    <!-- Fill the above text with question -->\n",
    "    <!-- Fill the above text with question -->\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a27720c-32cb-44c7-a037-fc7a77b6fcc9",
   "metadata": {},
   "source": [
    "<div style=\"background-color: lightgreen; color: black; padding: 4px;\">\n",
    "    <h3>Data Pipeline\n",
    "</h3> </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98308a57",
   "metadata": {},
   "source": [
    "A data pipeline is a method in which raw data is ingested from various data sources, transformed and then ported to a data store, such as a data lake or data warehouse, for analysis. \n",
    "\n",
    "Before data flows into a data repository, it usually undergoes some data processing.\n",
    "\n",
    "data transformations, such as filtering, masking, and aggregations\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2842daa",
   "metadata": {},
   "source": [
    "![image.png](https://media.geeksforgeeks.org/wp-content/uploads/20240923183059/data-pipeline-Overview.webp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de287146",
   "metadata": {},
   "source": [
    "![image.png](https://estuary.dev/static/66e6cb47ada993cb3d0e713e1300968d/64ce4/a546ea_02_data_pipeline_architecture_ETL_a016c380be.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfe8bdab",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "49dcabe0",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "28962ca7-3365-43cc-8378-ecd0c5fe0917",
   "metadata": {},
   "source": [
    "<div style=\"background-color: lightblue; color: black; padding: 4px;\">\n",
    "    <h4> Types of Data Pipelines\n",
    "</h4> </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b7080b3",
   "metadata": {},
   "source": [
    "- **Batch Data Pipelines:** Interact with large portions of data all at once and at some specific time of the day.\n",
    "\n",
    "- **Real-Time Data Pipelines:** Interact with data at the time of its creation for almost real-time outcome.\n",
    "\n",
    "- **Cloud-Native Data Pipelines:** Built for running in cloud environments which are more malleable and more flexible.\n",
    "\n",
    "- **Open-Source Data Pipelines:** Created with the implementation of the open-source technologies like Apache Kafka, Airflow or Spark."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7285386e-c68b-4c9b-af08-0d18fe2dc368",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c0369c7c",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9cc9b4e9-bc75-48d4-853e-b176194e1581",
   "metadata": {},
   "source": [
    "<div style=\"background-color: lightblue; color: black; padding: 4px;\">\n",
    "    <h4> ETL Process\n",
    "</h4> </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fa7010d",
   "metadata": {},
   "source": [
    "![image-2.png](https://media.geeksforgeeks.org/wp-content/uploads/ETL.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0e3dfd5-4d36-4ade-9584-975425db32e1",
   "metadata": {},
   "source": [
    "<div style=\"background-color: lightblue; color: black; padding: 4px;\">\n",
    "    <h4> Apache Airflow\n",
    "</h4> </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01acebae",
   "metadata": {},
   "source": [
    "an open-source platform designed to programmatically author, schedule, and monitor workflows(a series of tasks in a particular order).\n",
    "\n",
    "\n",
    "\n",
    "well-suited for managing complex data pipelines and is widely used in the fields of data warehousing, data analytics, and data engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19c960f5",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "Used to Build Schedule Run data pipelines at scale\n",
    "\n",
    "- https://airflow.apache.org/use-cases/etl_analytics/\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a0875d8",
   "metadata": {},
   "source": [
    "- Apache airflow documentation - https://airflow.apache.org/docs/apache-airflow/stable/index.html"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9bfa66a",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b01e6a0a",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "093ace22",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (3853413114.py, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[1], line 2\u001b[1;36m\u001b[0m\n\u001b[1;33m    python -m venv airflow_env\u001b[0m\n\u001b[1;37m              ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bae95cc4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0bd4a749",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b69ed7ea-1940-434d-bb2d-601d07994783",
   "metadata": {},
   "source": [
    "<div style=\"background-color: lightblue; color: white; padding: 10px; text-align: center;\">\n",
    "    <h1>_________________________________END________________________________\n",
    "        <!--- Mohammad Idrees Bhat | Tech Skills Trainer | AI/ML Consultant --->\n",
    "</h1> </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36cb6d13-361e-453b-b906-b18a963fd7fc",
   "metadata": {},
   "source": [
    "Some Additional Resources:\n",
    "\n",
    "- https://www.ibm.com/topics/data-warehouse\n",
    "- https://aws.amazon.com/what-is/data-warehouse/\n",
    "- https://www.datacamp.com/tutorial/guide-to-data-warehousing-on-aws-with-redshift\n",
    "- https://d1.awsstatic.com/training-and-certification/ramp-up_guides/Ramp-Up_Guide_Data_Analytics.pdf\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13e86481-eae2-4019-9515-66a43a30f0fb",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #002147; color: #fff; padding: 30px; text-align: center;\">\n",
    "    <h1>THANK YOU!\n",
    "        <!--- Mohammad Idrees Bhat | Tech Skills Trainer | AI/ML Consultant --->\n",
    "</h1> </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36f2d487-56ef-4c22-a1c9-d25e9df33e37",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\"  padding: 10px; text-align: center;\">\n",
    "    <font size=\"3\"> Programming Interveiw Questions</font>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4e08c3f-3e5b-46a6-9fbb-456cbd850553",
   "metadata": {},
   "source": [
    "##### 1. What is a data warehouse, and how does it differ from a traditional database?\n",
    "- **Follow-up:** Can you explain the key components of a data warehouse architecture?\n",
    "\n",
    "---\n",
    "\n",
    "##### 2. What is ETL, and what role does it play in data warehousing?\n",
    "- **Follow-up:** Can you describe the ETL process and give examples of tools used for ETL?\n",
    "\n",
    "---\n",
    "\n",
    "##### 3. Explain the difference between a star schema and a snowflake schema in data warehousing.\n",
    "- **Follow-up:** When would you choose one schema over the other?\n",
    "\n",
    "---\n",
    "\n",
    "##### 4. What is data normalization, and why is it important in the context of data warehousing?\n",
    "- **Follow-up:** Can you give an example of how normalization can affect data retrieval performance?\n",
    "\n",
    "---\n",
    "\n",
    "##### 5. How do you ensure data quality and integrity in a data warehouse?\n",
    "- **Follow-up:** What methods or tools do you use for data cleansing and validation during the ETL process?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20800262",
   "metadata": {},
   "source": [
    "### **SOLUTIONS**\n",
    "\n",
    "# Data Warehousing Interview Questions and Answers\n",
    "\n",
    "##### 1. What is a data warehouse, and how does it differ from a traditional database?\n",
    "A data warehouse is a centralized repository that stores large volumes of historical data from multiple sources, optimized for analysis and reporting. It differs from a traditional database in that:\n",
    "- **Purpose:** Databases are designed for transactional processing (CRUD operations), while data warehouses are designed for analytical processing (read-heavy operations).\n",
    "- **Data Structure:** Data warehouses use denormalized structures (e.g., star and snowflake schemas) to optimize query performance, whereas databases typically use normalized structures to reduce data redundancy.\n",
    "- **Data Source:** Data warehouses aggregate data from various operational systems, while databases usually serve a single application.\n",
    "\n",
    "---\n",
    "\n",
    "##### 2. What is ETL, and what role does it play in data warehousing?\n",
    "ETL stands for Extract, Transform, Load. It is a process used to:\n",
    "- **Extract** data from various source systems (e.g., databases, flat files).\n",
    "- **Transform** the data into a suitable format for analysis (e.g., cleaning, aggregating, converting data types).\n",
    "- **Load** the transformed data into the data warehouse.\n",
    "\n",
    "ETL is crucial because it prepares and consolidates data, ensuring it is accurate and reliable for reporting and analysis.\n",
    "\n",
    "---\n",
    "\n",
    "##### 3. Explain the difference between a star schema and a snowflake schema in data warehousing.\n",
    "- **Star Schema:** In a star schema, a central fact table is surrounded by dimension tables. The structure is denormalized, which simplifies queries and improves performance.\n",
    "  \n",
    "- **Snowflake Schema:** A snowflake schema is a more normalized version of the star schema, where dimension tables are further broken down into sub-dimensions. This can reduce data redundancy but may complicate queries and impact performance.\n",
    "\n",
    "**When to choose one over the other:**\n",
    "- Choose a star schema for simpler queries and better performance.\n",
    "- Choose a snowflake schema for better data integrity and when storage space is a concern.\n",
    "\n",
    "---\n",
    "\n",
    "##### 4. What is data normalization, and why is it important in the context of data warehousing?\n",
    "Data normalization is the process of organizing data in a database to minimize redundancy and dependency. In data warehousing, normalization is important because:\n",
    "- It improves data integrity by reducing anomalies during data operations.\n",
    "- It can simplify the structure of the data model, making it easier to maintain.\n",
    "\n",
    "However, in the context of data warehousing, too much normalization can lead to complex queries and slower performance, so a balance is often needed.\n",
    "\n",
    "---\n",
    "\n",
    "##### 5. How do you ensure data quality and integrity in a data warehouse?\n",
    "To ensure data quality and integrity, you can:\n",
    "- **Implement Data Validation Rules:** Use validation rules during the ETL process to check for accuracy and completeness.\n",
    "- **Use Data Profiling Tools:** Analyze data to understand its quality and identify issues before loading it into the warehouse.\n",
    "- **Conduct Regular Audits:** Perform data quality audits to check for inconsistencies or anomalies.\n",
    "\n",
    "**Methods and tools used:**\n",
    "- Tools like Apache Nifi, Talend, and Informatica can assist in data cleansing and validation during the ETL process.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5454f2e3-4fa4-48f9-936a-35be52d769af",
   "metadata": {},
   "source": [
    "<!--- Mohammad Idrees Bhat | Mohammad Idrees Bhat --->"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e92ba4c-672c-4e9f-b842-2b2d9234e5ff",
   "metadata": {},
   "source": [
    "<h2 style=\"background-color: #ffe4e1; color: #2f4f4f; padding: 10px; border-radius: 10px; width: 350px; text-align: center; float: right; margin: 20px 0;\">\n",
    "    Mohammad Idrees Bhat<br>\n",
    "    <span style=\"font-size: 12px; color: #696969;\">\n",
    "        Tech Skills Trainer | AI/ML Consultant\n",
    "    </span>\n",
    "</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15cc27b3-58d0-431e-8121-f1b4c08377c7",
   "metadata": {},
   "source": [
    "<!--- Mohammad Idrees Bhat | Tech Skills Trainer | AI/ML Consultant --->"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DABatch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
